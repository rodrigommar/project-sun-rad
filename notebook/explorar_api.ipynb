{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando o uso API\n",
    "\n",
    "### Recuperar estações automáticas (T)\n",
    "\n",
    "Recuperar todas estações de acordo com o tipo passado como parâmetro:<br>\n",
    "**URL BASE**:  https://apitempo.inmet.gov.br/estacoes/{type_station}<br>\n",
    "**type_station (automatica)**: T <br>\n",
    "**type_station (manual)**: M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Obter os dados de uma url\n",
    "def get_data(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "#  retorna dados de um tipo de estacão \n",
    "def estation_type(type_estation):\n",
    "    \n",
    "    url = f'https://apitempo.inmet.gov.br/estacoes/{type_estation}'\n",
    "    \n",
    "    data = get_data(url)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# concatenar os dados das estações Automaticas e Manauais\n",
    "def get_all_stations():\n",
    "    \n",
    "    estacoes_automaticas = estation_type('T')\n",
    "    estacoes_manuais = estation_type('M')\n",
    "\n",
    "    todas_estacoes = []\n",
    "    todas_estacoes.extend(estacoes_automaticas)\n",
    "    todas_estacoes.extend(estacoes_manuais)\n",
    "    \n",
    "    return todas_estacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções responsáveis por salvar dados em arquivos JSON e CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def export_json(data, file_name):\n",
    "    json_str = json.dumps(data, default=str)\n",
    "\n",
    "    with open(f'../data/{file_name}.json', 'w') as file:\n",
    "        file.write(json_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "def export_csv(data, file_name):\n",
    "    colunas = data[0].keys()\n",
    "\n",
    "    with open(f'../data/{file_name}.csv', 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=colunas)      \n",
    "        writer.writeheader()\n",
    "        \n",
    "        for linha in data:\n",
    "            writer.writerow(linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar dados da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os dados da API\n",
    "\n",
    "todas_estacoes = get_all_stations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar para JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_json(todas_estacoes, 'data_raw_all_stations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('../data/data_raw_all_stations.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação de dados:\n",
    "#### 1 - Exluir colunas ['SG_ENTIDADE']<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('SG_ENTIDADE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Tratar valores Nan nas colunas ['DT_FIM_OPERACAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Como todos os valores são Nan\n",
    "df.isna().sum()\n",
    "\n",
    "#2 - Vou atualizar todos os campos para zero(0) e mudar o Dtype para int64\n",
    "df['DT_FIM_OPERACAO'] = df['DT_FIM_OPERACAO'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Preencher os valores Nan da coluna ['FL_CAPITAL'] com o valor 'N'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - levando em consideração que a maioria estações não são capitais, vou atualizar os valores Nans com o valor 'N'\n",
    "\n",
    "df['FL_CAPITAL'].value_counts()\n",
    "\n",
    "#N    585\n",
    "#S     18\n",
    "#Nan  111\n",
    "#Name: FL_CAPITAL, dtype: int64\n",
    "\n",
    "\n",
    "df['FL_CAPITAL'] = df['FL_CAPITAL'].fillna('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4 - Formatar a coluna ['DT_INICIO_OPERACAO'] para exibir apenas a data no formato YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come é:\n",
    "# format: 2008-07-20T21:00:00.000-03:00\n",
    "\n",
    "# como será:\n",
    "# format: 2008-07-20\n",
    "\n",
    "# aplicar split() na string.\n",
    "df['DT_INICIO_OPERACAO'] = df['DT_INICIO_OPERACAO'].str.split('T').str[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar os dados:\n",
    "#### 1 - formato JSON.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro orient='records' indica que a lista de dicionários será preservada\n",
    "# O parâmetro lines=True cria um arquivo JSON de linhas, onde cada linha é um dicionário\n",
    "\n",
    "df.to_json('../data/data_processed_all_stations.json',orient='records')\n",
    "#df.to_json('../data/data_processed_all_stations.json',orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição das colunas\n",
    "\n",
    "**CD_OSCAR** : 'Código internacionalmente reconhecido para a estação meteorológica'  \n",
    "**DC_NOME** : 'Nome da estação meteorológica'  \n",
    "**FL_CAPITAL** : 'Indicação se a estação é a capital do estado (\"S\" para sim, \"N\" para não)'  \n",
    "**DT_FIM_OPERACAO** : 'Data de encerramento das operações da estação (pode ser nulo se ainda estiver em operação)'  \n",
    "**CD_SITUACAO** : 'Situação atual da estação meteorológica (por exemplo, \"Pane\")'  \n",
    "**TP_ESTACAO** : 'Tipo da estação meteorológica (por exemplo, \"Automática\")'  \n",
    "**VL_LATITUDE** : 'Valor da latitude geográfica da estação'  \n",
    "**CD_WSI** : 'Código único atribuído pela WSI (Weather Services International)'  \n",
    "**CD_DISTRITO** : 'Código do distrito ao qual a estação pertence'  \n",
    "**VL_ALTITUDE** : 'Altitude da estação meteorológica'  \n",
    "**SG_ESTADO** : 'Sigla do estado onde a estação está localizada'  \n",
    "**SG_ENTIDADE** : 'Sigla da entidade responsável pela estação meteorológica (por exemplo, \"INMET\")'  \n",
    "**CD_ESTACAO** : 'Código único atribuído à estação'  \n",
    "**VL_LONGITUDE** : 'Valor da longitude geográfica da estação'  \n",
    "**DT_INICIO_OPERACAO** : 'Data de início das operações da estação meteorológica'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
